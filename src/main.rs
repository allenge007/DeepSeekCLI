mod config;
mod history;
mod models;

use atty::Stream;
use clap::{Arg, Command, ArgAction, Subcommand};
use futures::StreamExt;
use reqwest::Client;
use std::io::{self, Write};
use std::sync::Arc;
use std::sync::atomic::{AtomicBool, Ordering};
use tokio::time::{sleep, Duration};

use config::{read_config, Config};
use history::*;
use models::{ChatMessage, ChatPayload, ResponseFormat, StreamingChunk};

#[derive(Subcommand)]
enum MemoryAction {
    /// æ–°å¯¹è¯ï¼ˆæ¸…ç©ºå†å²è®°å½•ï¼‰
    New,
    /// ç»§ç»­ä¸Šä¸€æ¬¡å¯¹è¯
    Continue,
}

struct CliArgs {
    mem_action: Option<MemoryAction>,
    query: String,
    model: String,
    temperature: f32,
    no_memory: bool,   // true è¡¨ç¤ºæ— è®°å¿†æ¨¡å¼
}

fn parse_args() -> CliArgs {
    let matches = Command::new("ag")
        .version("1.0")
        .about("ä½¿ç”¨ DeepSeek API è¿›è¡Œå¤šè½®å¯¹è¯ï¼Œå¹¶ç®¡ç†å¯¹è¯å†å²")
        .arg(Arg::new("query").help("æŸ¥è¯¢å†…å®¹").index(1))
        .arg(
            Arg::new("version")
                .short('v')
                .long("version")
                .default_value("v3")
                .help("æ¨¡å‹ç‰ˆæœ¬, r1 è¡¨ç¤º deepseek-reasoner"),
        )
        .arg(
            Arg::new("temperature")
                .short('t')
                .long("temperature")
                .default_value("1")
                .help("æ¸©åº¦ï¼ˆé»˜è®¤ï¼š1ï¼‰"),
        )
        // ä½¿ç”¨ --memory è¡¨ç¤ºè®°å¿†æ¨¡å¼ï¼Œå¦åˆ™ä¸ºæ— è®°å¿†æ¨¡å¼
        .arg(
            Arg::new("memory")
                .long("memory")
                .short('m')
                .help("è®°å¿†æ¨¡å¼ï¼šå¯ç”¨åæ¯æ¬¡è°ƒç”¨ API æ—¶ä¿å­˜å†å²è®°å½•")
                .action(ArgAction::SetTrue),
        )
        // å½“å¼€å¯è®°å¿†æ¨¡å¼æ—¶ï¼Œä»…å…è®¸ new æˆ– continue å­å‘½ä»¤
        .subcommand(
            Command::new("new")
                .about("æ–°å¯¹è¯")
                .arg(Arg::new("query").help("æŸ¥è¯¢å†…å®¹").index(1)),
        )
        .subcommand(
            Command::new("continue")
                .about("ç»§ç»­ä¸Šä¸€æ¬¡å¯¹è¯")
                .arg(Arg::new("query").help("æŸ¥è¯¢å†…å®¹").index(1)),
        )
        .get_matches();

    // å¦‚æœåœ¨è®°å¿†æ¨¡å¼ä¸‹ä¸”å­˜åœ¨å­å‘½ä»¤ï¼Œåˆ™ä¼˜å…ˆä»å­å‘½ä»¤ä¸­è·å–æŸ¥è¯¢å†…å®¹
    let query = if let Some(sub_m) = matches.subcommand_matches("new") {
        sub_m.get_one::<String>("query").unwrap_or_else(|| {
            eprintln!("è¯·æä¾›æŸ¥è¯¢å†…å®¹");
            std::process::exit(1);
        }).to_string()
    } else if let Some(sub_m) = matches.subcommand_matches("continue") {
        sub_m.get_one::<String>("query").unwrap_or_else(|| {
            eprintln!("è¯·æä¾›æŸ¥è¯¢å†…å®¹");
            std::process::exit(1);
        }).to_string()
    } else if let Some(q) = matches.get_one::<String>("query") {
        q.to_string()
    } else {
        eprintln!("è¯·æä¾›æŸ¥è¯¢å†…å®¹");
        std::process::exit(1);
    };

    let version = matches.get_one::<String>("version").unwrap();
    let model = if version == "r1" {
        "deepseek-reasoner".to_string()
    } else {
        "deepseek-chat".to_string()
    };

    let temperature = matches
        .get_one::<String>("temperature")
        .and_then(|t| t.parse::<f32>().ok())
        .unwrap_or(1.0);

    let memory = matches.get_flag("memory");
    // å½“è®°å¿†æ¨¡å¼å¼€å¯æ—¶ï¼Œå…è®¸ new æˆ– continue ä½œä¸ºå­å‘½ä»¤ï¼›å¦åˆ™å‡ä¸ºæ— è®°å¿†æ¨¡å¼
    let mem_action = if memory {
        if let Some(_) = matches.subcommand_matches("new") {
            Some(MemoryAction::New)
        } else {
            // æœªæŒ‡å®šé»˜è®¤ä¸º continue
            Some(MemoryAction::Continue)
        }
    } else {
        None
    };

    CliArgs {
        mem_action,
        query,
        model,
        temperature,
        no_memory: !memory,
    }
}

// å¯åŠ¨ spinnerï¼ˆä»…åœ¨ stdout ä¸º tty æ—¶æœ‰æ•ˆï¼‰
fn start_spinner(model: &str) -> (Option<Arc<AtomicBool>>, Option<tokio::task::JoinHandle<()>>) {
    if atty::is(Stream::Stdout) {
        let sr = Arc::new(AtomicBool::new(true));
        let sr_clone = sr.clone();
        let model = model.to_string();
        let handle = tokio::spawn(async move {
            let spinner_chars = vec!["|", "/", "-", "\\"];
            let mut idx = 0;
            while sr_clone.load(Ordering::Relaxed) {
                eprint!("\r{}ğŸ¤–: {}", model, spinner_chars[idx % spinner_chars.len()]);
                io::stderr().flush().unwrap();
                idx += 1;
                sleep(Duration::from_millis(100)).await;
            }
            eprint!("\r                   \r");
            io::stderr().flush().unwrap();
        });
        (Some(sr), Some(handle))
    } else {
        (None, None)
    }
}

/// å¤„ç† SSE æµï¼Œå®æ—¶è¾“å‡º reasoning åŠå›ç­”ï¼Œè¿”å›æœ€ç»ˆå›ç­”å†…å®¹
async fn process_stream(
    model: &str,
    mut stream: impl futures::Stream<Item = Result<bytes::Bytes, reqwest::Error>> + Unpin,
    spinner_running: Option<Arc<AtomicBool>>,
    mut spinner_handle: Option<tokio::task::JoinHandle<()>>,
) -> Result<String, Box<dyn std::error::Error>> {
    let mut received_first_chunk = false;
    let mut thinking = true;
    let mut content = String::new();
    while let Some(item) = stream.next().await {
        let chunk = item?;
        let text = String::from_utf8_lossy(&chunk);
        for line in text.lines() {
            let line = line.trim();
            if line == "data: [DONE]" {
                return Ok(content);
            }
            if line.starts_with("data: ") {
                let data = line.trim_start_matches("data: ").trim();
                if !received_first_chunk {
                    if let Some(ref sr) = spinner_running {
                        sr.store(false, Ordering::Relaxed);
                    }
                    received_first_chunk = true;
                    if let Some(handle) = spinner_handle.take() {
                        handle.await?;
                    }
                    print!("\r{}ğŸ¤–:\n", model);
                }
                if let Ok(chunk_obj) = serde_json::from_str::<StreamingChunk>(data) {
                    if let Some(choice) = chunk_obj.choices.get(0) {
                        if let Some(delta) = &choice.delta {
                            // è¾“å‡ºæ€ç»´é“¾å†…å®¹
                            if let Some(reasoning) = &delta.reasoning_content {
                                for c in reasoning.chars() {
                                    print!("{}", c);
                                    content.push(c);
                                    io::stdout().flush().unwrap();
                                    sleep(Duration::from_millis(10)).await;
                                }
                                println!("\n");
                            }
                            // è¾“å‡ºæœ€ç»ˆå›ç­”
                            if let Some(delta_content) = &delta.content {
                                if model == "deepseek-reasoner" && thinking {
                                    thinking = false;
                                    println!("\nanswer:\n");
                                }
                                for c in delta_content.chars() {
                                    print!("{}", c);
                                    content.push(c);
                                    io::stdout().flush().unwrap();
                                    sleep(Duration::from_millis(10)).await;
                                }
                            }
                        }
                    }
                }
            }
        }
    }
    Ok(content)
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // è§£æä¸»è¦å‚æ•°
    let cli = parse_args();
    let currnt_history_path = &current_history_path();

        // è¯»å–ç®¡é“ä¼ è¾“çš„å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
    let mut piped_input = String::new();
    if !atty::is(Stream::Stdin) {
        // ä»æ ‡å‡†è¾“å…¥è¯»å–ç®¡é“å†…å®¹
        use std::io::Read;
        io::stdin().read_to_string(&mut piped_input)?;
    }
    // æ‹¼æ¥ç®¡é“å†…å®¹ä¸å‘½ä»¤è¡ŒæŸ¥è¯¢å†…å®¹
    let final_query = if piped_input.trim().is_empty() {
        cli.query.clone()
    } else {
        format!("{}\n{}", piped_input.trim(), cli.query)
    };

    // æ ¹æ®è®°å¿†æ¨¡å¼åˆ¤æ–­å†å²åŠ è½½ä¸ä¿å­˜
    let mut history_messages = if cli.no_memory {
        Vec::new()
    } else if let Some(MemoryAction::New) = cli.mem_action {
        Vec::new()
    } else {
        // é»˜è®¤ä½¿ç”¨ continue æ¨¡å¼åŠ è½½å½“å‰å†å²è®°å½•
        load_history(&currnt_history_path)
    };

    // å°†ç”¨æˆ·æé—®åŠ å…¥å¯¹è¯å†å²
    history_messages.push(ChatMessage {
        role: "user".to_string(),
        content: final_query,
        reasoning_content: None,
        tool_calls: None,
    });

    let payload = ChatPayload {
        model: cli.model.clone(),
        messages: history_messages.clone(),
        frequency_penalty: 0,
        max_tokens: 2048,
        presence_penalty: 0,
        response_format: ResponseFormat { typ: "text".to_string() },
        stop: None,
        stream: true,
        stream_options: Some(serde_json::json!({ "include_usage": true })),
        temperature: cli.temperature,
        top_p: 1.0,
        tools: None,
        tool_choice: "none".to_string(),
        logprobs: false,
        top_logprobs: None,
    };

    let cfg: Config = read_config()
        .expect("è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶ ~/.config/deepseek/config.toml æ ¼å¼");
    let api_key = cfg.api_key;
    let baseurl = "https://api.deepseek.com/chat/completions";
    let client = Client::new();
    let response = client
        .post(baseurl)
        .header("Authorization", format!("Bearer {}", api_key))
        .json(&payload)
        .send()
        .await?;

    if !response.status().is_success() {
        let err_text = response.text().await?;
        eprintln!("\x1b[31mAPI è¿”å›é”™è¯¯: {}\x1b[0m", err_text);
        std::process::exit(1);
    }

    let (spinner_running, spinner_handle) = start_spinner(&cli.model);
    let content = process_stream(
        &cli.model,
        response.bytes_stream(),
        spinner_running,
        spinner_handle,
    ).await?;

    println!();

    if !cli.no_memory {
        let mut new_history = payload.messages;
        new_history.push(ChatMessage {
            role: "assistant".to_string(),
            content: content.clone(),
            reasoning_content: None,
            tool_calls: None,
        });
        if let Some(MemoryAction::Continue) = cli.mem_action {
            delete_history(&currnt_history_path)?;
        }
        save_history(&new_history)?;
        // ç»¿è‰²æç¤º
        println!("\x1b[32må†å²è®°å½•å·²ä¿å­˜ï¼Œä¸‹ä¸€è½®å¯¹è¯è‡ªåŠ¨ç»§ç»­ä¸Šä¸€æ¬¡çš„å¯¹è¯ã€‚\x1b[0m");
    } else {
        // é»„è‰²æç¤º
        println!("\x1b[33mæ— è®°å¿†æ¨¡å¼ä¸‹ï¼Œä¸ä¿å­˜å†å²è®°å½•ã€‚\x1b[0m");
    }

    Ok(())
}